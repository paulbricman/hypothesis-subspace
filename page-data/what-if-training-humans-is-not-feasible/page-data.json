{"componentChunkName":"component---node-modules-gatsby-theme-garden-src-templates-local-file-js","path":"/what-if-training-humans-is-not-feasible","result":{"data":{"file":{"childMdx":{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"What if training humans is not feasible?\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"what-if-training-humans-is-not-feasible\"\n  }, \"What if training humans is not feasible?\"), mdx(\"p\", null, \"Perhaps the internal representations used by the ML model are so alien that trying to teach humans this foreign language would fail spectacularly. The main source of replies to this family of counterarguments might come from the fact that the ML model itself is incentivized to use its representational resources efficiently, striking a balance between \\\"speaker economy\\\" and \\\"message clarity\\\". We have reasons to believe the ML model's internal language and human languages might exhibit convergent evolution due to the perks of resource efficiency.\"), mdx(\"p\", null, \"Still, despite the ML model coming up with its own internal \\\"mathematical\\\" instead of \\\"written multiple-paragraph\\\", for various parts of its conceptual framework, it might still be too advanced. Imagine having to learn Chinese in one-week tops (as an attempt to artificially constrain capabilities and at the same time boost the difficulty of a human-made problem into superhuman territory). Alternatively, imagine teaching non-human primates to write coherent English by pressing on a keyboard. Unlikely to happen to a reliable extent.\"), mdx(\"p\", null, \"This feels like the opposite side of the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/what-if-the-bottleneck-layer-is-too-constraining\",\n    \"title\": \"what-if-the-bottleneck-layer-is-too-constraining\"\n  }, \"[[what-if-the-bottleneck-layer-is-too-constraining]]\"), \" struggle. It might be interesting to add additional constraints on the internal representation inspired by \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/representational-alignment\",\n    \"title\": \"representational-alignment\"\n  }, \"[[representational-alignment]]\"), \" to help bring the two modes of thought closer, in order to avoid this clash in sophistication. This might refer to both making the model's representations easier to perceive (the realm of \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/bridger-languages\",\n    \"title\": \"bridger-languages\"\n  }, \"[[bridger-languages]]\"), \"), but also closer to the human thing (the realm of \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/representational-alignment\",\n    \"title\": \"representational-alignment\"\n  }, \"[[representational-alignment]]\"), \").\"), mdx(\"p\", null, \"Another approach would be to split the task of acquiring the ML model's language into subtask through a chain of bridger languages. The whole chain would be learned by the ML model, where each element of the chain would be constrained to be within a threshold of divergence (e.g. KL divergence) with its neighboring languages. Additionally, the one end of the chain would have to be a human language. Following this, people would gradually learn to bridge the representational gap. Potentially, new generations might gradually move across the gap, each internalizing a more alien version of the language, which would come to feel natural.\"));\n}\n;\nMDXContent.isMDXComponent = true;","outboundReferences":[{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"What if the bottleneck layer is too constraining?\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"what-if-the-bottleneck-layer-is-too-constraining\"\n  }, \"What if the bottleneck layer is too constraining?\"), mdx(\"p\", null, \"Enforcing local structure over latent activations and forcing their components to conform to a cookbook of quantized vectors might result in an inconvenient alignment tax on the performance of ML models, despite making internal representations more human-friendly. Fortunately, the few techniques available todayfor improving the interpretability of ML models using conventional transparency tools (e.g. SoLU) don't seem to incur significant capability penalties, which is encouraging.\"), mdx(\"p\", null, \"Still, it might be the case that one \\\"sentence\\\" expressed in the interlingua takes one person a lot of time to parse out and understand. Local structure constraints might help break down the representations into decently decoupled chunks before people reconvening to piece the puzzle. It's unclear how much this could scale, though. Imagine tasking a thousand people with reading one page of a thousand-page book, before reconvening. This runs into HCH-like conceptual limitations.\"), mdx(\"p\", null, \"Conversely, instead of horizontally splitting out the interlingua sentence, one might imagine a hierarchical variation which contains a top-level representation before zooming in on meanings. In the hexagonal toy example from \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/how-might-an-interlingua-look-like\",\n    \"title\": \"how-might-an-interlingua-look-like\"\n  }, \"[[how-might-an-interlingua-look-like]]\"), \", one might imagine having a top-level lattice, where each symbol can be zoomed into, resulting in a nested lattice. Flows of information during learning, and hence the resulting local structure, would match the links contained in the hierarchy. That said, the devil might lost be in low-level details of combinatorial size.\"));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"bf907c45-4476-5076-b0fd-0cef3c5870ef","fields":{"slug":"/what-if-the-bottleneck-layer-is-too-constraining","title":"What if the bottleneck layer is too constraining?"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Representational Alignment\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"representational-alignment\"\n  }, \"Representational Alignment\"), mdx(\"p\", null, \"As a step in aligning AGI to human intent, we might want to first align the latent representations of ML models with the latent representations of humans. This would mean bypassing human language and behavior entirely, and incentivizing the ML model to make use of representations which can accurately be translated to and from neural activity. This should generally ensure that human representations and human representations alone are employed by the ML model in its internal thought process. Finally, as a slider of capability, we might gradually shift towards relaxing the translatability constrain by applying it to model \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"shards\"), \" only, rather than holistically. This is analogous to a team of developers working on a codebase, where each one is only responsible for a chunk of it. The codebase is still represented in human brains, but no single brain represents it.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/how-does-representational-alignment-relate-to-concrete-challenges-in-alignment\",\n    \"title\": \"how-does-representational-alignment-relate-to-concrete-challenges-in-alignment\"\n  }, \"[[how-does-representational-alignment-relate-to-concrete-challenges-in-alignment]]\"), \"\")));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"175de8ae-a21d-56db-8fd2-27699bd740d6","fields":{"slug":"/representational-alignment","title":"Representational Alignment"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Bridger Languages\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"bridger-languages\"\n  }, \"Bridger Languages\"), mdx(\"p\", null, \"Interpretability tools generally assume no prior training on the part of humans when dissecting a model's internal representations. What if we allowed for explicit human training in a bridging language which is directly employed by a model? This might require us to apply principles of cognitive ergonomics to a bottleneck layer (e.g. sparsity, local structure, discreteness, Gestalt-aware symbols), so that humans could become fluent in the bridging language. A nested lattice of quantized \\\"logograms\\\" might be fitting, and young children might be particularly fit for the role of bridging the two different modes of thought. Pairs of artifacts in familiar modalities (e.g. text, images, videos) and associated translations could form the basis of the learning process, together with any discovered syntax of the emerging language.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/how-do-bridger-languages-relate-to-concrete-challenges-in-alignment\",\n    \"title\": \"how-do-bridger-languages-relate-to-concrete-challenges-in-alignment\"\n  }, \"[[how-do-bridger-languages-relate-to-concrete-challenges-in-alignment]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/how-does-the-best-case-scenario-for-bridger-languages-sound-like\",\n    \"title\": \"how-does-the-best-case-scenario-for-bridger-languages-sound-like\"\n  }, \"[[how-does-the-best-case-scenario-for-bridger-languages-sound-like]]\"), \"\")));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"3ab0b7b0-6877-526c-b13a-7f15ce7f5792","fields":{"slug":"/bridger-languages","title":"Bridger Languages"}}}],"inboundReferences":[{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"How does the base case scenario for bridger languages sound like?\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"how-does-the-base-case-scenario-for-bridger-languages-sound-like\"\n  }, \"How does the base case scenario for bridger languages sound like?\"), mdx(\"p\", null, \"After people getting used to using synthetic interlingua for gaining insight into the internal representations of ML models, the previous approach of dealing with high-dimensional vectors in forced ways would feel like going back to doing maths in written multiple-paragraph proofs, rather than using compact mathematical notation. That is, the current version would feel infinitely less expressive and brain-friendly than the interlingua. Moreover, the process of engineering latent activations to be more cognitively ergonomic would feel like a natural complement to the process of adapting humans to deal with unwieldy ML models through augmentation. It would help make the model's thoughts more easy to be perceived by humans.\"), mdx(\"p\", null, \"Planning, and ideation in lucrative domains (e.g. scientific research) remains difficult for humans to do, but proves easy for humans to verify, providing humanity deeper oversight abilities to help keep AGI in check. This might mean unraveling plans for human disempowerment, getting our hands on latent knowledge of advanced technologies, etc. In a sense, the model would be transparent from day one, before any transparency tool would be employed to timidly open the black box.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/how-might-an-interlingua-look-like\",\n    \"title\": \"how-might-an-interlingua-look-like\"\n  }, \"[[how-might-an-interlingua-look-like]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/what-if-the-bottleneck-layer-is-too-constraining\",\n    \"title\": \"what-if-the-bottleneck-layer-is-too-constraining\"\n  }, \"[[what-if-the-bottleneck-layer-is-too-constraining]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/what-if-training-humans-is-not-feasible\",\n    \"title\": \"what-if-training-humans-is-not-feasible\"\n  }, \"[[what-if-training-humans-is-not-feasible]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/what-if-interlingua-is-an-attack-vector\",\n    \"title\": \"what-if-interlingua-is-an-attack-vector\"\n  }, \"[[what-if-interlingua-is-an-attack-vector]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/how-to-handle-interlingua-dialects\",\n    \"title\": \"how-to-handle-interlingua-dialects\"\n  }, \"[[how-to-handle-interlingua-dialects]]\"), \"\")));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"957720e2-6f9c-53fe-944e-c4f30dd458a1","fields":{"slug":"/how-does-the-best-case-scenario-for-bridger-languages-sound-like","title":"How does the base case scenario for bridger languages sound like?"}}}]},"fields":{"slug":"/what-if-training-humans-is-not-feasible","title":"What if training humans is not feasible?"}}},"pageContext":{"id":"cd6362e8-2d2d-5819-a8da-e5f1fa4f0879"}},"staticQueryHashes":["2098632890","2221750479","2468095761"]}