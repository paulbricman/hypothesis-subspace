{"componentChunkName":"component---node-modules-gatsby-theme-garden-src-templates-local-file-js","path":"/differentiable-cosmogonies","result":{"data":{"file":{"childMdx":{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Differentiable Cosmogonies\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"differentiable-cosmogonies\"\n  }, \"Differentiable Cosmogonies\"), mdx(\"p\", null, \"Training a model on data about the world (e.g. Wikipedia, books, articles, papers, etc.) makes it difficult to box, as it's likely to exploit loopholes in the world (e.g. from physics to sociology) based on its evidence. Given this, we could build a one-way model-to-human channel by tasking the model with \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"learning a physics\"), \" which reliably causes lifelike structures to emerge from noise, before us gleaning insights from the resulting structures in a Voyager-pretending-Earth-is-alien sort of way. Life could be operationalized as entropy-fighting across space (e.g. forming unlikely chunks of matter) and time (e.g. changing in unlikely ways from moment to moment), while the physics to be learned could be modeled by a transformer mapping particle-tokens from one timestep to the next. Local-only interactions could help fight the quadratic attention costs, while particle-tokens could have slots for velocity, momentum, and chemical properties, depending on the targeted level of abstraction.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/how-do-differentiable-cosmogonies-relate-to-concrete-challenges-in-alignment\",\n    \"title\": \"how-do-differentiable-cosmogonies-relate-to-concrete-challenges-in-alignment\"\n  }, \"[[how-do-differentiable-cosmogonies-relate-to-concrete-challenges-in-alignment]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/how-would-a-training-story-look-like-for-differentiable-colonies\",\n    \"title\": \"how-would-a-training-story-look-like-for-differentiable-colonies\"\n  }, \"[[how-would-a-training-story-look-like-for-differentiable-colonies]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/how-do-differentiable-cosmogonies-relate-to-microscope-ai\",\n    \"title\": \"how-do-differentiable-cosmogonies-relate-to-microscope-ai\"\n  }, \"[[how-do-differentiable-cosmogonies-relate-to-microscope-ai]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/could-we-understand-emerging-aliens\",\n    \"title\": \"could-we-understand-emerging-aliens\"\n  }, \"[[could-we-understand-emerging-aliens]]\"), \"\")));\n}\n;\nMDXContent.isMDXComponent = true;","outboundReferences":[{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"How do differentiable cosmogonies relate to concrete challenges in alignment?\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"how-do-differentiable-cosmogonies-relate-to-concrete-challenges-in-alignment\"\n  }, \"How do differentiable cosmogonies relate to concrete challenges in alignment?\"), mdx(\"p\", null, \"Differentiable cosmogonies avoid the whole clash of human and AI intents over the shape of the world by sequestering the AI to a simulation which contains as little information as possible about the human world. This is meant as an attempt to avoid breakout through newly-detected loopholes. Unfortunately, this drastically reduces the usefulness of AI per unit of compute, because it requires a massive particle-resolution simulation over a massive number of timesteps. A few technical tricks might help shave off a few OOMs of compute (e.g. constrain particles to local interaction), but that doesn't even start unpacking the problem of translating the insights devised by replicators into human terms beyond Rorschach make-believe. Regardless, it aims to sidestep the challenge of intent alignment as a whole.\"));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"1bc5b28c-b202-5103-b3c6-9e8f0173f1c6","fields":{"slug":"/how-do-differentiable-cosmogonies-relate-to-concrete-challenges-in-alignment","title":"How do differentiable cosmogonies relate to concrete challenges in alignment?"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"How would a training story look like for differentiable colonies?\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"how-would-a-training-story-look-like-for-differentiable-colonies\"\n  }, \"How would a training story look like for differentiable colonies?\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Initialize the simulation. This consists in randomly placing particles across the available N-dimensional space and randomly filling up their potential property slots. Let the totality of particles describe the state of the simulation.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Run the simulation state through a transformer as a feed-forward pass. The resulting set of particles is then piped again through the same transformer. Each pass describes one discrete timestep of the simulation.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"After a fixed number of timesteps, stop the simulation and measure the \\\"lifelihood\\\" of the final part of the simulation, the end game. This is based on (1) the amount of information contained in the final simulation states individually (i.e. spatial entropy), and (2) the amount of information contained in the sequence of final simulation states as a whole (i.e. temporal entropy).\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Backpropagate through the unrolled transformer chain to incentivize it to maximize the lifelihood. How about maximum \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"lifelihood\"), \" estimation?\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Repeat steps 1-4 a large number of times (based on different simulation seeds), to train the model to reliably turn noise into high-lifelihood simulations.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"If replicators culture emerges, try to translate the knowledge they synthesized into human-legible terms. In a sense, you'd learn from artificial and general intelligences without them having strong priors on the seed human world.\")));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"af24cb56-33f6-552c-855a-1d1607f9a238","fields":{"slug":"/how-would-a-training-story-look-like-for-differentiable-colonies","title":"How would a training story look like for differentiable colonies?"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"How do differentiable cosmogonies relate to Microscope AI?\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"how-do-differentiable-cosmogonies-relate-to-microscope-ai\"\n  }, \"How do differentiable cosmogonies relate to Microscope AI?\"), mdx(\"p\", null, \"Similarities:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Both avoid deploying agentic systems.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Both rely on gaining knowledge from an ML model or its sandboxed output.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"They both likely fail to account for Meta deploying unaligned AGI six months later.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The interpretability aspect of unfamiliar structures (e.g. ML model weights, alien replicators) appears to be the most difficult step of the proposals.\")), mdx(\"p\", null, \"Differences:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Differentiable cosmogonies rely on gleaning information from the simulation implemented by an ML model, while Microscope AI relies on gleaning information from the \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"weights\"), \" of the ML model.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Microscope AI relies on training the ML model on data about our world, while differentiable cosmogonies as a paradigm rely on keeping the ML model as isolated as possible from information about our world.\")));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"18fc02ec-441a-50eb-8510-d65c7b27f8bf","fields":{"slug":"/how-do-differentiable-cosmogonies-relate-to-microscope-ai","title":"How do differentiable cosmogonies relate to Microscope AI?"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Could we understand emerging aliens?\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"could-we-understand-emerging-aliens\"\n  }, \"Could we understand emerging aliens?\"), mdx(\"p\", null, \"The point of differentiable cosmogonies is to cause boxed aliens into being and learn from them. Their aliennes to human technology and the physics of our world would help ensure the difficulty of breaking out of the box.\"), mdx(\"p\", null, \"However, there is a concern which plagues this approach, besides the likely insane amounts of compute necessary to run a tiny universe. If they're so alien to us, how could we communicate outside the realm of mathematics? Conversely, if we'd try to make them more related to us so that we could better understand them, they'd have more knowledge at their disposal to break out of the box (e.g. by persuading the observers to do so). There's a fundamental trade-off here, and it seems difficult to get the best of both worlds. Completely sacrificing familiarity would restrict us to gaining insight into mathematics, which is still appealing, but defeats the purpose of trying to run an entire physical universe, rather than just boxing a narrow AI who is good at maths. This way of looking at it points to an iteration of \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/differentiable-cosmogonies\",\n    \"title\": \"differentiable-cosmogonies\"\n  }, \"[[differentiable-cosmogonies]]\"), \" involving \\\"learning from boxed aliens\\\" in a general sense, rather than by simulating a tabula rasa universe. Alien here would mean unfamiliar with the human world.\"), mdx(\"p\", null, \"Could we keep them within legible range while still instilling an aversion to knowledge of humans and of the human world? Such an aversion could be detected and counterproductively bring more attention to the conceptual repellers, considering alien develop computer-like technology to tackle problems which are not cognitively ergonomic for them. Though if knowledge of the human world would be prevented from being physically realizable in the simulation, that might still perhaps patch the issue. But what if issue-patching and concept realizability develops as an unpatched conceptual territory considered in alien science? That might still point at the meta level.\"));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"66e6543b-1b43-504c-82f3-b284d815dedf","fields":{"slug":"/could-we-understand-emerging-aliens","title":"Could we understand emerging aliens?"}}}],"inboundReferences":[{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Home\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"home\"\n  }, \"Home\"), mdx(\"p\", null, \"This is the root note of a (mostly) tree-shaped document which contains my work at \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.alignmentforum.org/posts/D7epkkJb3CqDTYgX9/refine-an-incubator-for-conceptual-alignment-research-bets\"\n  }, \"Refine\"), \", an incubator for conceptual research on alignment hosted by \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.alignmentforum.org/posts/jfq2BH5kfQqu2vYv3/we-are-conjecture-a-new-alignment-research-startup\"\n  }, \"Conjecture\"), \". I'm using this fellowship as an opportunity to explore several prosaic themes which I currently find promising, and get better at the poking process itself.\"), mdx(\"p\", null, \"Reading all depth-one theme notes should take you around five minutes \\u2014 a deliberate design choice to help you get a quick sense of what this is all about. Afterwards, I recommend switching to a depth-first traversal on whatever branch you find interesting.\"), mdx(\"p\", null, \"I'd find it extremely helpful to hear any targeted feedback you might have via the note-linked comment threads. If possible, consider phrasing it as leading questions which I can then turn into new branches from the note you're commenting on. Best viewed on desktop.\"), mdx(\"h2\", {\n    \"id\": \"themes\"\n  }, \"Themes\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/ideological-inference-engines\",\n    \"title\": \"ideological-inference-engines\"\n  }, \"[[ideological-inference-engines]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/oversight-leagues\",\n    \"title\": \"oversight-leagues\"\n  }, \"[[oversight-leagues]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/concept-programming\",\n    \"title\": \"concept-programming\"\n  }, \"[[concept-programming]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/latent-resonators\",\n    \"title\": \"latent-resonators\"\n  }, \"[[latent-resonators]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/bridger-languages\",\n    \"title\": \"bridger-languages\"\n  }, \"[[bridger-languages]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/representational-alignment\",\n    \"title\": \"representational-alignment\"\n  }, \"[[representational-alignment]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/symbiont-sandboxes\",\n    \"title\": \"symbiont-sandboxes\"\n  }, \"[[symbiont-sandboxes]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/differentiable-cosmogonies\",\n    \"title\": \"differentiable-cosmogonies\"\n  }, \"[[differentiable-cosmogonies]]\"), \"\")), mdx(\"h2\", {\n    \"id\": \"appendix\"\n  }, \"Appendix\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/benchmark-scenarios\",\n    \"title\": \"benchmark-scenarios\"\n  }, \"[[benchmark-scenarios]]\"), \"\")));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"571e6790-8b07-5840-82d8-0562f06bb3c9","fields":{"slug":"/hello","title":"Home"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Could we understand emerging aliens?\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"could-we-understand-emerging-aliens\"\n  }, \"Could we understand emerging aliens?\"), mdx(\"p\", null, \"The point of differentiable cosmogonies is to cause boxed aliens into being and learn from them. Their aliennes to human technology and the physics of our world would help ensure the difficulty of breaking out of the box.\"), mdx(\"p\", null, \"However, there is a concern which plagues this approach, besides the likely insane amounts of compute necessary to run a tiny universe. If they're so alien to us, how could we communicate outside the realm of mathematics? Conversely, if we'd try to make them more related to us so that we could better understand them, they'd have more knowledge at their disposal to break out of the box (e.g. by persuading the observers to do so). There's a fundamental trade-off here, and it seems difficult to get the best of both worlds. Completely sacrificing familiarity would restrict us to gaining insight into mathematics, which is still appealing, but defeats the purpose of trying to run an entire physical universe, rather than just boxing a narrow AI who is good at maths. This way of looking at it points to an iteration of \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/differentiable-cosmogonies\",\n    \"title\": \"differentiable-cosmogonies\"\n  }, \"[[differentiable-cosmogonies]]\"), \" involving \\\"learning from boxed aliens\\\" in a general sense, rather than by simulating a tabula rasa universe. Alien here would mean unfamiliar with the human world.\"), mdx(\"p\", null, \"Could we keep them within legible range while still instilling an aversion to knowledge of humans and of the human world? Such an aversion could be detected and counterproductively bring more attention to the conceptual repellers, considering alien develop computer-like technology to tackle problems which are not cognitively ergonomic for them. Though if knowledge of the human world would be prevented from being physically realizable in the simulation, that might still perhaps patch the issue. But what if issue-patching and concept realizability develops as an unpatched conceptual territory considered in alien science? That might still point at the meta level.\"));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"66e6543b-1b43-504c-82f3-b284d815dedf","fields":{"slug":"/could-we-understand-emerging-aliens","title":"Could we understand emerging aliens?"}}}]},"fields":{"slug":"/differentiable-cosmogonies","title":"Differentiable Cosmogonies"}}},"pageContext":{"id":"2c3721b1-5de3-5ea1-b694-4055ec9c8136"}},"staticQueryHashes":["2098632890","2221750479","2468095761"]}