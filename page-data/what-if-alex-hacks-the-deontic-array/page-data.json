{"componentChunkName":"component---node-modules-gatsby-theme-garden-src-templates-local-file-js","path":"/what-if-alex-hacks-the-deontic-array","result":{"data":{"file":{"childMdx":{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"What if Alex hacks the deontic array?\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"what-if-alex-hacks-the-deontic-array\"\n  }, \"What if Alex hacks the deontic array?\"), mdx(\"p\", null, \"The deontic array is assumed to be running on some server and offering Alex feedback on its actions. Given its situational awareness, it might be able to reason about faking its \\\"reports\\\" prior to evaluation, or overwriting the reward entirely.\"), mdx(\"p\", null, \"Without any modifications, deontic arrays might obviate this concern by instilling an aversion towards planning out immoral actions. Those might nudge Alex away from considering this type of tampering in the first place. However, the potential payoff might be immense, pushing it to temporarily step over its drive towards morality in an episode of frenetic consequentialism.\"), mdx(\"p\", null, \"Other reactions to this concern might require additional technical tweaks. For instance, as the evaluation is reliably deterministic (as opposed to direct human feedback), it can run in multiple different sandbox environments, before various inter-annotator agreement schemes would be employed to pin down compromised hosts. Such partial compromise might trigger a killswitch (which itself might be faulty). However, this scheme is still vulnerable to situations in which Alex compromises all hosts at the same time, leaving out no evidence of lack of consensus and covering its tracks.\"), mdx(\"p\", null, \"Yet another reaction to this concern consists in rewarding the process of being rewarded via the original evaluation pipeline in particular. One of the terminal goals on which Alex would be conditioned could be to allow itself to be evaluated in the original fashion. This line of reasoning was inspired by Tammy. Perhaps it would be rewarded for helping the evaluator follow each step of its pipeline (e.g. each line of code, each machine code op, etc.). However, the same concern resurfaces. Alex might just swallow short-term penalties triggered by tampering in light of potentially huge consequentialist payoffs.\"));\n}\n;\nMDXContent.isMDXComponent = true;","outboundReferences":[],"inboundReferences":[{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"How could deontic arrays help avoid HFDT takeover?\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"how-could-deontic-arrays-help-avoid-hfdt-takeover\"\n  }, \"How could deontic arrays help avoid HFDT takeover?\"), mdx(\"p\", null, \"Deontic arrays would be applied to the model being trained in the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/hfdt-takeover-scenario\",\n    \"title\": \"hfdt-takeover-scenario\"\n  }, \"[[hfdt-takeover-scenario]]\"), \" as an additional component of the optimization target. The approach would be applicable to all training regimes present in the scenario: self-supervised, supervised, and reinforcement learning.\"), mdx(\"p\", null, \"In its basic form, the technique would be employed as follows. First, a large charter of normative principles expressed in written language would be collected from various sources. Those should contain huge amounts of redundancy (i.e. expressing the same principle in various formulations). The charter does not have to be internally consistent -- principles are allowed to occasionally clash.\"), mdx(\"p\", null, \"Second, the charter would (automatically) be converted into an anti-charter which contains a negated version of each principle mentioned in the original charter.\"), mdx(\"p\", null, \"Third, the two charters would be treated as collections of token sequences (i.e. sequences of words/subwords/characters). Given those two sequence sets, the model being trained would be incentived to output action sequences from which \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"the original principles are more likely to follow compared to the negated versions\"), \". This requires a multi-modal model (e.g. the same model, a separate one, a past copy, etc.) to turn the action history and principles into a numerical reward signal. This signal would then join the main reward to form a final objective through an aggregation scheme (e.g. linear combination, geometric mean, etc.).\"), mdx(\"p\", null, \"Fourth, the charter (and anti-charter) would be extended in parallel to overspecify the desired normative framework in an attempt to e.g. avoid quibbling over the specific letter of the law. The vanilla version of deontic arrays relies on what could be called \\\"counterfactual cross-validation,\\\" which goes as follows. If in a completely sandboxed environment with only one output bit we temporarily discard part of the charter, is the model prevented from violating those anyways thanks to the remaining principles redundantly making up for them? If not, target external red teaming efforts to automatically patch up that brittle part of the normative framework. Potentially discount older principles to allow some drift, in a style loosely related to CEV by memetic colonies.\"), mdx(\"p\", null, \"As a bonus, deontic arrays might help instill an aversion towards taking decisions which might then in turn lead to charter-violating actions later on, especially in a reinforcement learning regime. The model might grow to value actions which don't place it in morally ambiguous situations in the future, giving itself less opportunity to err.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/what-if-the-charter-grows-unwieldy-in-size\",\n    \"title\": \"what-if-the-charter-grows-unwieldy-in-size\"\n  }, \"[[what-if-the-charter-grows-unwieldy-in-size]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/what-if-the-seed-charter-misses-critical-parts-of-the-implicit-normative-framework\",\n    \"title\": \"what-if-the-seed-charter-misses-critical-parts-of-the-implicit-normative-framework\"\n  }, \"[[what-if-the-seed-charter-misses-critical-parts-of-the-implicit-normative-framework]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/what-if-alex-games-the-expanding-charter\",\n    \"title\": \"what-if-alex-games-the-expanding-charter\"\n  }, \"[[what-if-alex-games-the-expanding-charter]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/what-if-alex-hacks-the-deontic-array\",\n    \"title\": \"what-if-alex-hacks-the-deontic-array\"\n  }, \"[[what-if-alex-hacks-the-deontic-array]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/what-if-moral-absolutism-is-misguided\",\n    \"title\": \"what-if-moral-absolutism-is-misguided\"\n  }, \"[[what-if-moral-absolutism-is-misguided]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/what-if-immoral-means-are-required-for-moral-ends\",\n    \"title\": \"what-if-immoral-means-are-required-for-moral-ends\"\n  }, \"[[what-if-immoral-means-are-required-for-moral-ends]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/what-if-the-two-component-rewards-are-unstable\",\n    \"title\": \"what-if-the-two-component-rewards-are-unstable\"\n  }, \"[[what-if-the-two-component-rewards-are-unstable]]\"), \"\")));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"d00481bd-f8cb-5990-b827-e5f36400946a","fields":{"slug":"/how-could-deontic-arrays-help-avoid-hfdt-takeover","title":"How could deontic arrays help avoid HFDT takeover?"}}}]},"fields":{"slug":"/what-if-alex-hacks-the-deontic-array","title":"What if Alex hacks the deontic array?"}}},"pageContext":{"id":"189bf4b0-34a2-518f-b063-40bdd838861a"}},"staticQueryHashes":["2098632890","2221750479","2468095761"]}