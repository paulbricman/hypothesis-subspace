{"componentChunkName":"component---node-modules-gatsby-theme-garden-src-templates-local-file-js","path":"/how-does-the-inherited-field-theory-apply","result":{"data":{"file":{"childMdx":{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"How does the inherited field theory apply?\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"how-does-the-inherited-field-theory-apply\"\n  }, \"How does the inherited field theory apply?\"), mdx(\"p\", null, \"A large part of \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/deontic-arrays\",\n    \"title\": \"deontic-arrays\"\n  }, \"[[deontic-arrays]]\"), \" as an inherited part of ideological inference engines was the idea of a field defined using discrete structures across a state space. In its main formulation, IIE seem to lack that otherwise promising focus. How can it be recovered?\"), mdx(\"p\", null, \"First, one way to recover this connection would be to consider the entailment verifier as yielding a continuous value denoting compatibility of the knowledge base with the verification target. This would be opposed to a GOFAI-like boolean output of this component. This fuzzier output would allow us to define a landscape of compatibility with the knowledge base across action space, and hence provide gradients for guiding model state towards compatible regions and away from incompatible ones.\"), mdx(\"p\", null, \"However, this is not immediately intuitive considering the expectation that only one verification target is picked and undergoes verification at a time. In a sense, a whole space of actions would need to undergo verification in order to help specify that gradient. Maybe one could investigate KB \\u22A8 A where A would be a \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"space\"), \" of actions, rather than a single one. And instead of yielding a single fuzzy estimate of compatibility, it would yield this space of compatibilities as an output.\"), mdx(\"p\", null, \"Additionally, the direct connection between discrete items contained in the knowledge base and those compatibility gradients is now less visible. When visualizing magnet-like structures for each KB item, it's intuitive to think of how each individual item is influencing the model. However, the grouping of items in a global KB before yielding compatibility gradients through entailment obscures this connection somewhat. The individual contributions to shaping the field are aggregated before having a say.\"));\n}\n;\nMDXContent.isMDXComponent = true;","outboundReferences":[{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Deontic Arrays\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"deontic-arrays\"\n  }, \"Deontic Arrays\"), mdx(\"p\", null, \"What if we engineered discreteness into the objective function, while preserving the appeal of end-to-end differentiability? A finite set of discrete structures (e.g. attractors, repellers, dipoles, etc.) could be used to exert force on a model and influence its dynamics, a bit like DeepMind actively \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.deepmind.com/blog/accelerating-fusion-science-through-learned-plasma-control\"\n  }, \"shaping plasma\"), \" inside a fusion reactor using a set of magnets. In the case of deontic arrays, individual structures could be human principles, while the target shape would correspond to a region of state space deemed safe. The discreteness of deontology (i.e. finite sets of moral laws) lends itself nicely to various generalization schemes, such as cross-validation followed by \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.deepmind.com/publications/red-teaming-language-models-with-language-models\"\n  }, \"targeted red teaming\"), \". Deontic arrays could also populate a host of different state spaces (e.g. latent space during inference, model space during training, optimizer space during meta-learning, etc.).\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/how-do-deontic-arrays-relate-to-concrete-challenges-in-alignment\",\n    \"title\": \"how-do-deontic-arrays-relate-to-concrete-challenges-in-alignment\"\n  }, \"[[how-do-deontic-arrays-relate-to-concrete-challenges-in-alignment]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/how-could-deontic-arrays-help-avoid-hfdt-takeover\",\n    \"title\": \"how-could-deontic-arrays-help-avoid-hfdt-takeover\"\n  }, \"[[how-could-deontic-arrays-help-avoid-hfdt-takeover]]\"), \"\")));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"ba9d0692-6b49-5964-a4b9-b6d7d4d0f455","fields":{"slug":"/deontic-arrays","title":"Deontic Arrays"}}}],"inboundReferences":[{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Ideological Inference Engines\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"ideological-inference-engines\"\n  }, \"Ideological Inference Engines\"), mdx(\"p\", null, \"Ideological inference engines are at the same time a generalization and merger of \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/memetic-colonies\",\n    \"title\": \"memetic-colonies\"\n  }, \"[[memetic-colonies]]\"), \" and \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/deontic-arrays\",\n    \"title\": \"deontic-arrays\"\n  }, \"[[deontic-arrays]]\"), \", connecting the two previous approaches into a shared framework while combining their strengths. In general, this framework relies on expanding an initial knowledge base meant to capture human values using LLMs and promoting courses of action which are compatible with the resulting expansion. Every ideological inference engine has the following ingredients:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"knowledge base\"), \" (KB): The initial seed aiming to capture human values. In \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/deontic-arrays\",\n    \"title\": \"deontic-arrays\"\n  }, \"[[deontic-arrays]]\"), \", this was a fixed-length charter containing normative principles. In \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/memetic-colonies\",\n    \"title\": \"memetic-colonies\"\n  }, \"[[memetic-colonies]]\"), \", this was a position in a debate between competing memeplexes. In general, the knowledge based is a finite set of sequences. Those sequences can be propositional (e.g. normative principles), but might also be behavioral (e.g. state-action trajectories).\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"inference mechanism\"), \" (\\u22A2): The procedure for systematically expanding the knowledge base. In \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/deontic-arrays\",\n    \"title\": \"deontic-arrays\"\n  }, \"[[deontic-arrays]]\"), \", this procedure was based on a mix of counterfactual cross-validation and targeted red teaming. In \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/memetic-colonies\",\n    \"title\": \"memetic-colonies\"\n  }, \"[[memetic-colonies]]\"), \", this was based on investigating multiple memetic phylogenies in a setting of competitive pressure. The inference mechanism might also be a naive forward-chaining procedure, inspired by \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/memetic-colonies\",\n    \"title\": \"memetic-colonies\"\n  }, \"[[memetic-colonies]]\"), \", but without competitive pressures (i.e. just incentives for internal consistency).\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"entailment verifier\"), \" (\\u22A8): Given an (expanded) knowledge base, the procedure for approving different courses of action. In \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/memetic-colonies\",\n    \"title\": \"memetic-colonies\"\n  }, \"[[memetic-colonies]]\"), \", this was based on Overton probing of textual content or textual descriptions of non-textual content. In \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/deontic-arrays\",\n    \"title\": \"deontic-arrays\"\n  }, \"[[deontic-arrays]]\"), \", this was based on counterfactual likelihood (i.e. checking whether principles where more likely to follow than negated principles). Similarly to previous ingredients, the generalized framing also accepts a wider variety of approches for verifiers.\")), mdx(\"p\", null, \"IIEs relate to GOFAI inference engines in several intuitive ways. For instance, both roughly rely on expanding a knowledge base using an inference engine and then using the expanded knowledge base to verify a new item. Additionally, they both run into similar issues. How to handle a combinatorial explosion of the knowledge base when relying on forward-chaining in complex domains? How to handle infinite loops if working with backward-chaining (i.e. reasoning backwards)? Solutions identified in GOFAI might help alleviate analogous ones in IIE.\"), mdx(\"p\", null, \"However, there are important conceptual differences between the two. For one, the whole set of clean inference rules discussed in GOFAI settings (e.g. Modus Ponents, Modus Tolens, etc.) are imperfectly handled by LLMs in the current context. Inevitably, the messiness of language as a representation medium (though a behavioral KB might also work), combined with the messiness of human values expressed in said medium make for a fuzzier and more opaque inference engine. The KB only contains true atoms, while LLMs handle all the implicit rules to relate them to new ones, in a somewhat awkward mix-up of the meanings of \\\"model\\\" and \\\"knowledge base\\\" across the two settings. Still, the similarities and structure provided by the framework seem compelling.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/what-is-the-relation-between-the-knowledge-base-and-approved-actions\",\n    \"title\": \"what-is-the-relation-between-the-knowledge-base-and-approved-actions\"\n  }, \"[[what-is-the-relation-between-the-knowledge-base-and-approved-actions]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/how-would-backward-chaining-work-in-ideological-inference-engines\",\n    \"title\": \"how-would-backward-chaining-work-in-ideological-inference-engines\"\n  }, \"[[how-would-backward-chaining-work-in-ideological-inference-engines]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/how-does-the-inherited-field-theory-apply\",\n    \"title\": \"how-does-the-inherited-field-theory-apply\"\n  }, \"[[how-does-the-inherited-field-theory-apply]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/how-do-ideological-inference-engines-resist-gaming\",\n    \"title\": \"how-do-ideological-inference-engines-resist-gaming\"\n  }, \"[[how-do-ideological-inference-engines-resist-gaming]]\"), \"\")));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"2fc92a94-4cc4-5fb3-9c8a-ddef2f1166c7","fields":{"slug":"/ideological-inference-engines","title":"Ideological Inference Engines"}}}]},"fields":{"slug":"/how-does-the-inherited-field-theory-apply","title":"How does the inherited field theory apply?"}}},"pageContext":{"id":"12aaa3c8-b3cd-55b9-812e-46cebfb9372e"}},"staticQueryHashes":["2098632890","2221750479","2468095761"]}