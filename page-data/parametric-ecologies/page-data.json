{"componentChunkName":"component---node-modules-gatsby-theme-garden-src-templates-local-file-js","path":"/parametric-ecologies","result":{"data":{"file":{"childMdx":{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Parametric Ecologies\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"parametric-ecologies\"\n  }, \"Parametric Ecologies\"), mdx(\"p\", null, \"Life is arguably the primordial world-optimizer, with biotic factors being known to have caused \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.sciencedirect.com/science/article/pii/S0960982215010908\"\n  }, \"major shifts\"), \" in the abiotic world to suit their needs: oxygen-rich atmosphere, fertile soils, etc. We find ourselves in a \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/The_Blind_Watchmaker\"\n  }, \"\\\"blind watchmaker\\\"\"), \" position where we can bring into existence systems beyond our comprehension by merely defining a computational niche and applying optimization pressure. One way of modeling niche-bound ecologies is in term of their inputs and outputs: what kinds of energy and matter they consume in relation to what they offer for others to consume. If framing ML models as ecologies adapting to an (often unnaturally fixed) computational niche, all sorts of neat parallels arise: transfer learning as exaptation, instrumental convergence as convergent evolution, regularizers as stressors enforcing resilience, gradualism, meta-learning as internal selection, etc. From here, we could build on ideas from ecosystem engineering and remnants of cybernetics (which, temptingly, means \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"steersman\"), \") to explore the vocabulary of stable \\\"arrangements\\\" of ecologies, similar to the clever setups involved in backtranslation, diffusion, or adversarial training.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/how-do-parametric-ecologies-relate-to-concrete-challenges-in-alignment\",\n    \"title\": \"how-do-parametric-ecologies-relate-to-concrete-challenges-in-alignment\"\n  }, \"[[how-do-parametric-ecologies-relate-to-concrete-challenges-in-alignment]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/what-holds-and-what-breaks-in-the-parametric-ecologies-analogy\",\n    \"title\": \"what-holds-and-what-breaks-in-the-parametric-ecologies-analogy\"\n  }, \"[[what-holds-and-what-breaks-in-the-parametric-ecologies-analogy]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/what-low-hanging-safety-mechanisms-are-parametric-ecologies-hinting-at\",\n    \"title\": \"what-low-hanging-safety-mechanisms-are-parametric-ecologies-hinting-at\"\n  }, \"[[what-low-hanging-safety-mechanisms-are-parametric-ecologies-hinting-at]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/are-training-arrangements-inspired-by-parametric-ecologies-likely-to-have-capability-externalities\",\n    \"title\": \"are-training-arrangements-inspired-by-parametric-ecologies-likely-to-have-capability-externalities\"\n  }, \"[[are-training-arrangements-inspired-by-parametric-ecologies-likely-to-have-capability-externalities]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/how-would-the-language-of-parametric-ecologies-look-like\",\n    \"title\": \"how-would-the-language-of-parametric-ecologies-look-like\"\n  }, \"[[how-would-the-language-of-parametric-ecologies-look-like]]\"), \"\")));\n}\n;\nMDXContent.isMDXComponent = true;","outboundReferences":[{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"How do parametric ecologies relate to concrete challenges in alignment?\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"how-do-parametric-ecologies-relate-to-concrete-challenges-in-alignment\"\n  }, \"How do parametric ecologies relate to concrete challenges in alignment?\"), mdx(\"p\", null, \"As this theme encourages a somewhat different frame for ML as a whole, its direct applications to alignment are not immediately apparent. One application would be as a language for assembling collections of models into self-regulating systems trained end-to-end to avoid imbalances (e.g. mode collapse in GAN training). Another application would be an approach to preserving internal features of an ecology (e.g. human values) during a shift to a different computational niche (e.g. new capabilities). In this, parametric ecologies tackle concerns related to unbounded optimization and objective robustness.\"));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"4a14619e-8d08-5889-99e9-fce3f2b8f859","fields":{"slug":"/how-do-parametric-ecologies-relate-to-concrete-challenges-in-alignment","title":"How do parametric ecologies relate to concrete challenges in alignment?"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"What holds and what breaks in the parametric ecologies analogy?\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"what-holds-and-what-breaks-in-the-parametric-ecologies-analogy\"\n  }, \"What holds and what breaks in the parametric ecologies analogy?\"), mdx(\"p\", null, \"Holds:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Both ecologies and ML models have inputs and outputs. The former in the form of energy and metabolic pathways, the latter in the form of data.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Both ecologies and ML models exhibit exaptation. In ecologies, this translates to dynamics developed in a niche being reused in a different niche. In ML models, this translates to transfer learning and pre-training/fine-tuning practices.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Both ecologies and ML models exhibit gradualism. In ecologies, you wouldn't get complexity like the human eye if simpler eyes wouldn't have helped a bit at least in the past. In ML models, you wouldn't get certain behaviors if previous changes towards them wouldn't have led to improvements.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Both ecologies and ML models grow resilient from redundancy. In ecology, this translates to multiple energy pathways making species resilient against one food source disappearing. In ML models, this translates to Dropout/DropConnect-like regularizers encouraging what I'd call \\\"internal ensembles\\\" reaching a sensible consensus despite one pathway going wacky.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Both ecologies and ML models exhibit covergent dynamics. In ecology, this translates to convergent evolution (e.g. flight having been rediscovered multiple times on Earth because it's useful in certain niches). In ML models, this translates to instrumental convergence and something akin to natural abstractions (e.g. varied models trained on face recognition form anatomical abstractions independently).\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Both ecologies and ML models lend themselves to co-evolution loops. In ecology, this translates to both cooperative (e.g. symbionts growing interdependent) and competitive (e.g. leopard and antelopes both getting faster). In ML models, this translates to training setups involving multiple models (e.g. generator and discriminator co-evolving in GANs).\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Both ecologies and ML models lend themselves to optimization pressure. In ecology, this translates to evolutionary pressure to adapt to available niches. In ML models, this translates to optimization pressure exercised via gradient descent.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Both ecologies and ML models lack intelligent design. In ecology, this translates to Darwinism. In ML models, this translated to ML as opposed to rule-based/symbolic/non-ML methods.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Both ecologies and ML models can shape their inputs. In ecologies, this translates to biotic influences over abiotic stuffs. In ML models, this translates to learned embeddings which accumulate gradients despite being at the bottom of the \\\"trophic chain\\\" and not serving any other role other than to be consumed.\")), mdx(\"p\", null, \"Partially holds:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Many ML models are optimized to fit fixed computational niches. In contrast, ecologies subtly influence each other over time, and hence drift away from their initial niches. However, some ML training paradigms exhibit non-fixed niches. Any regime involving multiple models is one such case (as they're mutually defining each other's niche). Additionally, individual models trained to reverse corruptions (e.g. denoising, diffusion, language modeling, masked language modeling, etc.) are occasionally re-defining their own niche by defining the stable shape of this external object (e.g. cascades, self-distillation).\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"It's unclear what the individual members of the trophic chain are. Individual neurons? Individual layers? Individual blocks (e.g. transformer encoder block containing multiple simpler layers)? Multiple choices are compatible with the analogy, especially if individuals are not internally influencing or feeding on themselves.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"It's not perfectly clear to me how reinforcement learning would be framed in this input-output niche setting. Perhaps environment states are inputs, actions are outputs, but what about reward? This ecology isn't tasked with fitting a particular computational niche, because we don't know how that would look like. We're guiding by fitness directly, sort of?\")));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"19b18345-02fe-5652-a013-7688dc8f14ff","fields":{"slug":"/what-holds-and-what-breaks-in-the-parametric-ecologies-analogy","title":"What holds and what breaks in the parametric ecologies analogy?"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"What low-hanging safety mechanisms are parametric ecologies hinting at?\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"what-low-hanging-safety-mechanisms-are-parametric-ecologies-hinting-at\"\n  }, \"What low-hanging safety mechanisms are parametric ecologies hinting at?\"), mdx(\"p\", null, \"Perhaps a GAN-like setup for RL agents aiming to co-evolve agent-evaluator capabilities? The discriminator would be trained to recognize human behavior, while the generator would be trained to suggest them. At the end, you'd get a generator-agent and a discriminator-evaluator which yields a numerical reward for humanness, despite nobody specifying what that was in advance. The evaluator might grow into being a sensible evaluator, in a similar way to how a GAN discriminator gets a sense of which images are photorealistic and which are not.\"), mdx(\"p\", null, \"Alternatively, an ML model trained as an \\\"ecosystem engineer\\\" to correct divergences of a target object (e.g. BERT trying its best to revert masked tokens in a text, DALL-E 2 trying its best to revert noise sprinkled on an image), might help \\\"stabilize\\\" actions considered by an agent, and help avoid inappropriate courses of action.\"), mdx(\"p\", null, \"It seems to me, however, that both of those low-hanging safety tricks (e.g. stabilize policy, co-evolve evaluator with an agent which is itself increasing in capabilities) are applications of past model arrangements and training regimes. Coming up with new schemes might unfortunately benefit capabilities quite drastically, just like the previous ones. Related: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/are-training-arrangements-inspired-by-parametric-ecologies-likely-to-have-capability-externalities\",\n    \"title\": \"are-training-arrangements-inspired-by-parametric-ecologies-likely-to-have-capability-externalities\"\n  }, \"[[are-training-arrangements-inspired-by-parametric-ecologies-likely-to-have-capability-externalities]]\"), \". I currently find it unlikely for newly discovered training regimes to differentially push safety further ahead. Still, having them roughly on par might not be a horrible state of affairs.\"));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"468f03be-bcff-5b63-b1a7-1ebec0b92429","fields":{"slug":"/what-low-hanging-safety-mechanisms-are-parametric-ecologies-hinting-at","title":"What low-hanging safety mechanisms are parametric ecologies hinting at?"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Are training arrangements inspired by parametric ecologies likely to have capability externalities?\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"are-training-arrangements-inspired-by-parametric-ecologies-likely-to-have-capability-externalities\"\n  }, \"Are training arrangements inspired by parametric ecologies likely to have capability externalities?\"), mdx(\"p\", null, \"Most model arrangements which seem compatible with the parametric ecologies framing (e.g. adversarial training, backtranslation, diffusion) have only been recognized as being so retroactively, in a descriptive way. Taking stock of those possible manifestations of a broader alphabet of arrangements, it seems that they've mostly been developed in order to specifically bolster capabilities. For instance, diffusion lead to unprecedented performance in image generation, and backtranslation has helped push the state-of-the-art on machine translation.\"), mdx(\"p\", null, \"This begs the question of whether pursuing research on parametric ecologies as a generalization of training regimes might similarly push capabilities. This feels like a sensible concern. Often, the best outcome seems to be that both (1) models developed for practical use, and (2) models developed to oversee and evaluate the former are being pushed further. In a sense, the concerning model might be kept in check by an evaluator which proxies human preferences, while both would co-evolve into higher capabilities at the same time. For instance, in a GAN-like training regime, both generator and discriminator improve steadily over time (given some experience in the alchemy of hyperparam tuning).\"), mdx(\"p\", null, \"However, that seems like a neutral outcome at best. What if the generator is a step ahead? Is it okay if the arms race escalates beyond human oversight capabilities? We'd ideally want training regimes and model arrangements which bolster the safety mechanisms and alignment-critical components in particular, and leave raw capabilities trailing a bit behind. We'd perhaps want a stronger focus on stability beyond the sensitive equilibrium of an arms race. The feasibility of this better outcome probably depends on the specifics and generativity of the parametric ecologies.\"), mdx(\"p\", null, \"What's more, scaling laws indicate that currently data availability is the main impediment against pushing the state of the art. As parametric ecologies focus on clever uses of data and models so as to guide learning with limited resources (e.g. denoising, backtranslation), it feels like this might be particularly problematic, as the general gain in capabilities might be counterfactually rare.\"));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"de771d68-8d8c-536e-aadb-646b96c8b180","fields":{"slug":"/are-training-arrangements-inspired-by-parametric-ecologies-likely-to-have-capability-externalities","title":"Are training arrangements inspired by parametric ecologies likely to have capability externalities?"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"How would the language of parametric ecologies look like?\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"how-would-the-language-of-parametric-ecologies-look-like\"\n  }, \"How would the language of parametric ecologies look like?\"), mdx(\"p\", null, \"Ingredients:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"learned maps\"), \" (directed solid arrow): ML models being trained\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"frozen maps\"), \" (directed dashed arrow): frozen ML models / non-ML maps\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"distances\"), \" (bidirectional solid arrow): divergence, distance\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"optimization pressure points\"), \" (+/- bubble): gradient ascent/descent\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"(modeled) distributions\"), \" (numbers with optional hats): input / output / misc distributiosn\")), mdx(\"p\", null, \"Design choices:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Numbered distributions over lettered ones because one model's output is another model's inputs in interesting arrangements. Over named ones because names create clutter.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Name learned maps by letter on tail. Shared weights translated to identical names across arrows.\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://e1.pcloud.link/publink/show?code=VZzS44ZWnePcvhLJWyjkri2TloCDJxRlv5y\"\n  }, \"whiteboard\")));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"345484af-cb3b-565e-9e47-033b490e41b4","fields":{"slug":"/how-would-the-language-of-parametric-ecologies-look-like","title":"How would the language of parametric ecologies look like?"}}}],"inboundReferences":[{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Oversight Leagues\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"oversight-leagues\"\n  }, \"Oversight Leagues\"), mdx(\"p\", null, \"Similar to how \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/ideological-inference-engines\",\n    \"title\": \"ideological-inference-engines\"\n  }, \"[[ideological-inference-engines]]\"), \" are a merger of \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/deontic-arrays\",\n    \"title\": \"deontic-arrays\"\n  }, \"[[deontic-arrays]]\"), \" and \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/memetic-colonies\",\n    \"title\": \"memetic-colonies\"\n  }, \"[[memetic-colonies]]\"), \", oversight leagues are a merger of ideas from \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/contrastive-dreaming\",\n    \"title\": \"contrastive-dreaming\"\n  }, \"[[contrastive-dreaming]]\"), \" and \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/parametric-ecologies\",\n    \"title\": \"parametric-ecologies\"\n  }, \"[[parametric-ecologies]]\"), \", an attempt to combine the strength of the previous frames. Oversight leagues rely on placing the agent-in-training and an overseer evaluator in a GAN-like co-evolving feedback loop (a training regime expressible in \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/parametric-ecologies\",\n    \"title\": \"parametric-ecologies\"\n  }, \"[[parametric-ecologies]]\"), \"), while keeping the evaluator one step ahead using robustness techniqies (of which \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/contrastive-dreaming\",\n    \"title\": \"contrastive-dreaming\"\n  }, \"[[contrastive-dreaming]]\"), \" is an example). Additionally, notions from league training are brought in to complete the frame. In general, an oversight league consists of:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"unilateral training signals\"), \": Ways of improving the performance of one single component of the agent-evaluator duo without making use of the other. For instance, \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/contrastive-dreaming\",\n    \"title\": \"contrastive-dreaming\"\n  }, \"[[contrastive-dreaming]]\"), \" or vanilla adversarial training. An evaluator might be trained to systematically predict its own blindspots.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"bilateral training signals\"), \": Ways of improving the performance of a component of the agent-evaluator duo using the other component. An evaluator might be trained to spot the agent's shortcomings, while an agent might be trained to pick up the evaluator's blindspots. Bilateral training signals further split into:\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"present exploitation\"), \": Training a component against the latest version of the opposite component.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"past exploitation\"), \": Training a component against all the past versions of the opposite component, or a tricky mixture thereof. This is meant to avoid a component forgetting to account for earlier exploitation strategies (based on \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.nature.com/articles/s41586-019-1724-z\"\n  }, \"league exploiters in AlphaStar\"), \").\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"future exploitation\"), \": Train a component against future versions of the opposite component by anticipating short-term counterplay. Consists in running optimization across an unrolled version of a (boxed!) version of the opponent which gets a few more optimization steps (based on \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/pdf/1611.02163.pdf\"\n  }, \"unrolled GANs\"), \").\")))), mdx(\"p\", null, \"The core idea behind oversight leagues is that the evaluator is helped to better understand its systematic blindspot in relation to the agent. The agent is helped in a similar way, but unilateral training signals can be used to keep the overseer one step ahead.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/what-are-concrete-evaluator-designs\",\n    \"title\": \"what-are-concrete-evaluator-designs\"\n  }, \"[[what-are-concrete-evaluator-designs]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/what-are-concrete-unilateral-training-signals\",\n    \"title\": \"what-are-concrete-unilateral-training-signals\"\n  }, \"[[what-are-concrete-unilateral-training-signals]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/what-if-the-agent-gets-one-step-ahead-by-chance\",\n    \"title\": \"what-if-the-agent-gets-one-step-ahead-by-chance\"\n  }, \"[[what-if-the-agent-gets-one-step-ahead-by-chance]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/what-if-evaluator-overfits-to-seed\",\n    \"title\": \"what-if-evaluator-overfits-to-seed\"\n  }, \"[[what-if-evaluator-overfits-to-seed]]\"), \"\")));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"c971cb02-84ce-519e-9675-1ed9fb428398","fields":{"slug":"/oversight-leagues","title":"Oversight Leagues"}}}]},"fields":{"slug":"/parametric-ecologies","title":"Parametric Ecologies"}}},"pageContext":{"id":"c2873cfd-4c2b-5e67-9123-9fbcd93e4de4"}},"staticQueryHashes":["2098632890","2221750479","2468095761"]}