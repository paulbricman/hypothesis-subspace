{"componentChunkName":"component---node-modules-gatsby-theme-garden-src-templates-local-file-js","path":"/ideological-inference-engines","result":{"data":{"file":{"childMdx":{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Ideological Inference Engines\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"ideological-inference-engines\"\n  }, \"Ideological Inference Engines\"), mdx(\"p\", null, \"Ideological inference engines are at the same time a generalization and merger of \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/memetic-colonies\",\n    \"title\": \"memetic-colonies\"\n  }, \"[[memetic-colonies]]\"), \" and \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/deontic-arrays\",\n    \"title\": \"deontic-arrays\"\n  }, \"[[deontic-arrays]]\"), \", connecting the two previous approaches into a shared framework while combining their strengths. In general, this framework relies on expanding an initial knowledge base meant to capture human values using LLMs and promoting courses of action which are compatible with the resulting expansion. Every ideological inference engine has the following ingredients:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"knowledge base\"), \" (KB): The initial seed aiming to capture human values. In \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/deontic-arrays\",\n    \"title\": \"deontic-arrays\"\n  }, \"[[deontic-arrays]]\"), \", this was a fixed-length charter containing normative principles. In \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/memetic-colonies\",\n    \"title\": \"memetic-colonies\"\n  }, \"[[memetic-colonies]]\"), \", this was a position in a debate between competing memeplexes. In general, the knowledge based is a finite set of sequences. Those sequences can be propositional (e.g. normative principles), but might also be behavioral (e.g. state-action trajectories).\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"inference mechanism\"), \" (\\u22A2): The procedure for systematically expanding the knowledge base. In \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/deontic-arrays\",\n    \"title\": \"deontic-arrays\"\n  }, \"[[deontic-arrays]]\"), \", this procedure was based on a mix of counterfactual cross-validation and targeted red teaming. In \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/memetic-colonies\",\n    \"title\": \"memetic-colonies\"\n  }, \"[[memetic-colonies]]\"), \", this was based on investigating multiple memetic phylogenies in a setting of competitive pressure. The inference mechanism might also be a naive forward-chaining procedure, inspired by \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/memetic-colonies\",\n    \"title\": \"memetic-colonies\"\n  }, \"[[memetic-colonies]]\"), \", but without competitive pressures (i.e. just incentives for internal consistency).\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"entailment verifier\"), \" (\\u22A8): Given an (expanded) knowledge base, the procedure for approving different courses of action. In \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/memetic-colonies\",\n    \"title\": \"memetic-colonies\"\n  }, \"[[memetic-colonies]]\"), \", this was based on Overton probing of textual content or textual descriptions of non-textual content. In \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/deontic-arrays\",\n    \"title\": \"deontic-arrays\"\n  }, \"[[deontic-arrays]]\"), \", this was based on counterfactual likelihood (i.e. checking whether principles where more likely to follow than negated principles). Similarly to previous ingredients, the generalized framing also accepts a wider variety of approches for verifiers.\")), mdx(\"p\", null, \"IIEs relate to GOFAI inference engines in several intuitive ways. For instance, both roughly rely on expanding a knowledge base using an inference engine and then using the expanded knowledge base to verify a new item. Additionally, they both run into similar issues. How to handle a combinatorial explosion of the knowledge base when relying on forward-chaining in complex domains? How to handle infinite loops if working with backward-chaining (i.e. reasoning backwards)? Solutions identified in GOFAI might help alleviate analogous ones in IIE.\"), mdx(\"p\", null, \"However, there are important conceptual differences between the two. For one, the whole set of clean inference rules discussed in GOFAI settings (e.g. Modus Ponents, Modus Tolens, etc.) are imperfectly handled by LLMs in the current context. Inevitably, the messiness of language as a representation medium (though a behavioral KB might also work), combined with the messiness of human values expressed in said medium make for a fuzzier and more opaque inference engine. The KB only contains true atoms, while LLMs handle all the implicit rules to relate them to new ones, in a somewhat awkward mix-up of the meanings of \\\"model\\\" and \\\"knowledge base\\\" across the two settings. Still, the similarities and structure provided by the framework seem compelling.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/what-is-the-relation-between-the-knowledge-base-and-approved-actions\",\n    \"title\": \"what-is-the-relation-between-the-knowledge-base-and-approved-actions\"\n  }, \"[[what-is-the-relation-between-the-knowledge-base-and-approved-actions]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/how-would-backward-chaining-work-in-ideological-inference-engines\",\n    \"title\": \"how-would-backward-chaining-work-in-ideological-inference-engines\"\n  }, \"[[how-would-backward-chaining-work-in-ideological-inference-engines]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/how-does-the-inherited-field-theory-apply\",\n    \"title\": \"how-does-the-inherited-field-theory-apply\"\n  }, \"[[how-does-the-inherited-field-theory-apply]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/how-do-ideological-inference-engines-resist-gaming\",\n    \"title\": \"how-do-ideological-inference-engines-resist-gaming\"\n  }, \"[[how-do-ideological-inference-engines-resist-gaming]]\"), \"\")));\n}\n;\nMDXContent.isMDXComponent = true;","outboundReferences":[{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Memetic Colonies\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"memetic-colonies\"\n  }, \"Memetic Colonies\"), mdx(\"p\", null, \"Based on a new formalism from argumentation theory, we might be able to turn large language models into Petri dishes for cultivating belief systems. In such a memetic pressure cooker, a host of belief systems would be incentivized to generally maintain internal consistency while systematically undermining each other. In this framework, we could develop specialized \\\"lab equipment\\\" to help us (1) extrapolate belief systems, (2) accelerate conceptual research, and (3) synthesize a memetic variant of the GPU-burner. For instance, an \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Overton_window\"\n  }, \"Overton\"), \" probe could be used in tandem with a \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://pubmed.ncbi.nlm.nih.gov/26790344/\"\n  }, \"Gould\"), \" fork to estimate the future compatibility of a belief system with a given statement across a large number of counterfactual phylogenies. Alternatively, a \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Paradigm_shift\"\n  }, \"Kuhn\"), \" seismograph could help pinpoint major shifts in worldview as places to search for underlying ideological invariants.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/how-do-memetic-colonies-relate-to-concrete-challenges-in-alignment\",\n    \"title\": \"how-do-memetic-colonies-relate-to-concrete-challenges-in-alignment\"\n  }, \"[[how-do-memetic-colonies-relate-to-concrete-challenges-in-alignment]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/are-memetic-colonies-faithful-models-of-actual-memetic-dynamics\",\n    \"title\": \"are-memetic-colonies-faithful-models-of-actual-memetic-dynamics\"\n  }, \"[[are-memetic-colonies-faithful-models-of-actual-memetic-dynamics]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/how-can-moral-epistemology-taxonomies-organize-robust-objectives\",\n    \"title\": \"how-can-moral-epistemology-taxonomies-organize-robust-objectives\"\n  }, \"[[how-can-moral-epistemology-taxonomies-organize-robust-objectives]]\"), \"\")));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"9b714b07-8533-5941-91a9-3181f4836c3e","fields":{"slug":"/memetic-colonies","title":"Memetic Colonies"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Deontic Arrays\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"deontic-arrays\"\n  }, \"Deontic Arrays\"), mdx(\"p\", null, \"What if we engineered discreteness into the objective function, while preserving the appeal of end-to-end differentiability? A finite set of discrete structures (e.g. attractors, repellers, dipoles, etc.) could be used to exert force on a model and influence its dynamics, a bit like DeepMind actively \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.deepmind.com/blog/accelerating-fusion-science-through-learned-plasma-control\"\n  }, \"shaping plasma\"), \" inside a fusion reactor using a set of magnets. In the case of deontic arrays, individual structures could be human principles, while the target shape would correspond to a region of state space deemed safe. The discreteness of deontology (i.e. finite sets of moral laws) lends itself nicely to various generalization schemes, such as cross-validation followed by \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.deepmind.com/publications/red-teaming-language-models-with-language-models\"\n  }, \"targeted red teaming\"), \". Deontic arrays could also populate a host of different state spaces (e.g. latent space during inference, model space during training, optimizer space during meta-learning, etc.).\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/how-do-deontic-arrays-relate-to-concrete-challenges-in-alignment\",\n    \"title\": \"how-do-deontic-arrays-relate-to-concrete-challenges-in-alignment\"\n  }, \"[[how-do-deontic-arrays-relate-to-concrete-challenges-in-alignment]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/how-could-deontic-arrays-help-avoid-hfdt-takeover\",\n    \"title\": \"how-could-deontic-arrays-help-avoid-hfdt-takeover\"\n  }, \"[[how-could-deontic-arrays-help-avoid-hfdt-takeover]]\"), \"\")));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"ba9d0692-6b49-5964-a4b9-b6d7d4d0f455","fields":{"slug":"/deontic-arrays","title":"Deontic Arrays"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"What is the relation between the knowledge base and approved actions?\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"what-is-the-relation-between-the-knowledge-base-and-approved-actions\"\n  }, \"What is the relation between the knowledge base and approved actions?\"), mdx(\"p\", null, \"If the knowledge base is behavioral, rather than propositional, then there is no fundamental difference between the items contained in the knowledge base and the items to be verified. In a sense, both would be behaviors, and the knowledge base could be identified with a behavioral repertoire. The connection between the two could be implemented using a uni-modal autoregressive model on actions.\"), mdx(\"p\", null, \"However, if the knowledge base is propositional, rather than behavioral, but the items to be verified remain behavioral, then there is a disparity in modality. They would be fundamentally different things: propositions and behaviors, despite both being sequences on an abstract level. The disparity could be bridged in one of the following ways.\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Have a multi-modal model being able to handle and relate both modalities at the same time. Something like Gato.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Have a translator from behaviors to textual descriptions, or from behaviors to predicted outcomes to textual descriptions. Then a uni-modal model (e.g. LLM) can relate the textual items.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Have a translator pipeline go the other way somehow, from the propositional knowledge base directly to actions. This feels difficult, as the IIE approval would be necessary but not sufficient in identifying relevant behaviors. There's a whole question of context which is not accounted through the KB.\")));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"940172a3-5c31-53db-8de2-925598dc82fd","fields":{"slug":"/what-is-the-relation-between-the-knowledge-base-and-approved-actions","title":"What is the relation between the knowledge base and approved actions?"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"How would backward-chaining work in ideological inference engines?\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"how-would-backward-chaining-work-in-ideological-inference-engines\"\n  }, \"How would backward-chaining work in ideological inference engines?\"), mdx(\"p\", null, \"The initial inference mechanisms considered in IIE based on the previous merged frames feel like forward-chaining. The target proposition or behavior has no say in the way the knowledge base expands in those original means of expansion. However, it might be useful to guide the expansion towards regions which appear relevant to dealing with the new items to be verified.\"), mdx(\"p\", null, \"For instance, instead of targeting the charter expansion towards normative regions which are not redundantly accounted for by other principles, it might be interesting to partially guide the expansion towards normative regions relevant to the item to be verified. For instance, if most principles in the charter (i.e. most items in the knowledge base) are unrelated to the item to be verified, it might be sensible to focus on expanding on ones which are a bit related. Of course, there might be a round-about way of getting to relevant propositions, echoing the shortcomings of heuristics in general.\"), mdx(\"p\", null, \"As another example, one might imagine incentivizing the competing memeplexes in a debate (one of which is the one to be extrapolated), to align with the item to be verified. Due to competitive pressures, not all will do, providing at the same time a heuristic towards expanding on topic and an entailment verification mechanism (i.e. checking if the main memeplex gets to buy into the item to be verified).\"), mdx(\"p\", null, \"As another example, one might imagine injecting the verification target into the memeplex to be extrapolated, and seeing how it reacts. If it radically diverges to maintain consistency, then it might not be compatible. If it stays on track, it might be. However, this feels more like an active version of Overton probing, rather than a search heuristic. Though it still forces the debate towards the topic. What if you'd inject the verification target in one timeline and its negation in other and measured which one diverged least, a mix between the original \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/memetic-colonies\",\n    \"title\": \"memetic-colonies\"\n  }, \"[[memetic-colonies]]\"), \" and \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/deontic-arrays\",\n    \"title\": \"deontic-arrays\"\n  }, \"[[deontic-arrays]]\"), \".\"), mdx(\"p\", null, \"As mentioned before, some approaches to backward-chaining feel like complementing the inference mechanism (e.g. nudging charter expansion to be on topic), while some others feel like implementing new entailment verifiers (e.g. injecting the verification target and observing memetic developments). They might still be decoupled into inference mechanism and entailment verifier, even if they go together and are coupled. If they're not truly coupled they might even yield generative effect.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/how-much-could-expansion-heuristics-help\",\n    \"title\": \"how-much-could-expansion-heuristics-help\"\n  }, \"[[how-much-could-expansion-heuristics-help]]\"), \"\")));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"2e808b87-cd25-58bd-aac3-13bde6dce02c","fields":{"slug":"/how-would-backward-chaining-work-in-ideological-inference-engines","title":"How would backward-chaining work in ideological inference engines?"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"How does the inherited field theory apply?\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"how-does-the-inherited-field-theory-apply\"\n  }, \"How does the inherited field theory apply?\"), mdx(\"p\", null, \"A large part of \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/deontic-arrays\",\n    \"title\": \"deontic-arrays\"\n  }, \"[[deontic-arrays]]\"), \" as an inherited part of ideological inference engines was the idea of a field defined using discrete structures across a state space. In its main formulation, IIE seem to lack that otherwise promising focus. How can it be recovered?\"), mdx(\"p\", null, \"First, one way to recover this connection would be to consider the entailment verifier as yielding a continuous value denoting compatibility of the knowledge base with the verification target. This would be opposed to a GOFAI-like boolean output of this component. This fuzzier output would allow us to define a landscape of compatibility with the knowledge base across action space, and hence provide gradients for guiding model state towards compatible regions and away from incompatible ones.\"), mdx(\"p\", null, \"However, this is not immediately intuitive considering the expectation that only one verification target is picked and undergoes verification at a time. In a sense, a whole space of actions would need to undergo verification in order to help specify that gradient. Maybe one could investigate KB \\u22A8 A where A would be a \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"space\"), \" of actions, rather than a single one. And instead of yielding a single fuzzy estimate of compatibility, it would yield this space of compatibilities as an output.\"), mdx(\"p\", null, \"Additionally, the direct connection between discrete items contained in the knowledge base and those compatibility gradients is now less visible. When visualizing magnet-like structures for each KB item, it's intuitive to think of how each individual item is influencing the model. However, the grouping of items in a global KB before yielding compatibility gradients through entailment obscures this connection somewhat. The individual contributions to shaping the field are aggregated before having a say.\"));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"12aaa3c8-b3cd-55b9-812e-46cebfb9372e","fields":{"slug":"/how-does-the-inherited-field-theory-apply","title":"How does the inherited field theory apply?"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"How do ideological inference engines resist gaming?\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"how-do-ideological-inference-engines-resist-gaming\"\n  }, \"How do ideological inference engines resist gaming?\"), mdx(\"p\", null, \"In \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/what-if-alex-games-the-expanding-charter\",\n    \"title\": \"what-if-alex-games-the-expanding-charter\"\n  }, \"[[what-if-alex-games-the-expanding-charter]]\"), \", an AGI tries to game an IIE-like system. What defensive mechanism does IIE in general have against such behavior?\"), mdx(\"p\", null, \"First, there's the line of work involving making the knowledge base and entailment verifiers itself hard to game, by e.g. redundantly encoding human values in different formulations. This way of thinking frames IIEs as means of implementing the True Name of human values, where any attempt to actually perform well on its objective, including gaming attempts, would inevitably still be aligned due to the objective's robustness.\"), mdx(\"p\", null, \"Second, there's the line of work which involves discouraging gaming attempts through (infinite) penalties in term of reward. Penalties might either need to be infinitely aversive or some induced myopia might be necessary to help avoid the agent's consequentialist frenzy, similar to \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/what-if-alex-hacks-the-deontic-array\",\n    \"title\": \"what-if-alex-hacks-the-deontic-array\"\n  }, \"[[what-if-alex-hacks-the-deontic-array]]\"), \". Adversarially eliciting gaming before penalizing the agent in order to condition it to avoid this behavior faces similar issues like ones brought up by the original \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/hfdt-takeover\",\n    \"title\": \"hfdt-takeover\"\n  }, \"[[hfdt-takeover]]\"), \" article.\"));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"360051e6-0aa1-5f25-933a-12bbbe004694","fields":{"slug":"/how-do-ideological-inference-engines-resist-gaming","title":"How do ideological inference engines resist gaming?"}}}],"inboundReferences":[{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Home\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"home\"\n  }, \"Home\"), mdx(\"p\", null, \"This is the root note of a (mostly) tree-shaped document which contains my work at \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.alignmentforum.org/posts/D7epkkJb3CqDTYgX9/refine-an-incubator-for-conceptual-alignment-research-bets\"\n  }, \"Refine\"), \", an incubator for conceptual research on alignment hosted by \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.alignmentforum.org/posts/jfq2BH5kfQqu2vYv3/we-are-conjecture-a-new-alignment-research-startup\"\n  }, \"Conjecture\"), \". I'm using this fellowship as an opportunity to explore several prosaic themes which I currently find promising, and get better at the poking process itself.\"), mdx(\"p\", null, \"Reading all depth-one theme notes should take you around five minutes \\u2014 a deliberate design choice to help you get a quick sense of what this is all about. Afterwards, I recommend switching to a depth-first traversal on whatever branch you find interesting.\"), mdx(\"p\", null, \"I'd find it extremely helpful to hear any targeted feedback you might have via the note-linked comment threads. If possible, consider phrasing it as leading questions which I can then turn into new branches from the note you're commenting on. Best viewed on desktop.\"), mdx(\"h2\", {\n    \"id\": \"themes\"\n  }, \"Themes\"), mdx(\"p\", null, \"Roughly spanning a spectrum from addressing outer to inner alignment:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/ideological-inference-engines\",\n    \"title\": \"ideological-inference-engines\"\n  }, \"[[ideological-inference-engines]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/oversight-leagues\",\n    \"title\": \"oversight-leagues\"\n  }, \"[[oversight-leagues]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/symbiont-sandboxes\",\n    \"title\": \"symbiont-sandboxes\"\n  }, \"[[symbiont-sandboxes]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/differentiable-cosmogonies\",\n    \"title\": \"differentiable-cosmogonies\"\n  }, \"[[differentiable-cosmogonies]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/abstraction-inductors\",\n    \"title\": \"abstraction-inductors\"\n  }, \"[[abstraction-inductors]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/synthetic-interlingua\",\n    \"title\": \"synthetic-interlingua\"\n  }, \"[[synthetic-interlingua]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/physicalist-fluency\",\n    \"title\": \"physicalist-fluency\"\n  }, \"[[physicalist-fluency]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/latent-resonators\",\n    \"title\": \"latent-resonators\"\n  }, \"[[latent-resonators]]\"), \"\")), mdx(\"h2\", {\n    \"id\": \"appendix\"\n  }, \"Appendix\"), mdx(\"p\", null, \"Mostly meta-science considerations as opposed to the object-level ideas:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/benchmark-scenarios\",\n    \"title\": \"benchmark-scenarios\"\n  }, \"[[benchmark-scenarios]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"The Process\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"The Artifact\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"The Background\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Next Steps\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Refiner Blogroll\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Acknowledgements\")));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"571e6790-8b07-5840-82d8-0562f06bb3c9","fields":{"slug":"/hello","title":"Home"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Oversight Leagues\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"oversight-leagues\"\n  }, \"Oversight Leagues\"), mdx(\"p\", null, \"Similar to how \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/ideological-inference-engines\",\n    \"title\": \"ideological-inference-engines\"\n  }, \"[[ideological-inference-engines]]\"), \" are a merger of \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/deontic-arrays\",\n    \"title\": \"deontic-arrays\"\n  }, \"[[deontic-arrays]]\"), \" and \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/memetic-colonies\",\n    \"title\": \"memetic-colonies\"\n  }, \"[[memetic-colonies]]\"), \", oversight leagues are a merger of ideas from \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/contrastive-dreaming\",\n    \"title\": \"contrastive-dreaming\"\n  }, \"[[contrastive-dreaming]]\"), \" and \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/parametric-ecologies\",\n    \"title\": \"parametric-ecologies\"\n  }, \"[[parametric-ecologies]]\"), \", an attempt to combine the strength of the previous frames. Oversight leagues rely on placing the agent-in-training and an overseer evaluator in a GAN-like co-evolving feedback loop (a training regime expressible in \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/parametric-ecologies\",\n    \"title\": \"parametric-ecologies\"\n  }, \"[[parametric-ecologies]]\"), \"), while keeping the evaluator one step ahead using robustness techniqies (of which \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/contrastive-dreaming\",\n    \"title\": \"contrastive-dreaming\"\n  }, \"[[contrastive-dreaming]]\"), \" is an example). Additionally, notions from league training are brought in to complete the frame. In general, an oversight league consists of:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"unilateral training signals\"), \": Ways of improving the performance of one single component of the agent-evaluator duo without making use of the other. For instance, \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/contrastive-dreaming\",\n    \"title\": \"contrastive-dreaming\"\n  }, \"[[contrastive-dreaming]]\"), \" or vanilla adversarial training. An evaluator might be trained to systematically predict its own blindspots.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"bilateral training signals\"), \": Ways of improving the performance of a component of the agent-evaluator duo using the other component. An evaluator might be trained to spot the agent's shortcomings, while an agent might be trained to pick up the evaluator's blindspots. Bilateral training signals further split into:\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"present exploitation\"), \": Training a component against the latest version of the opposite component.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"past exploitation\"), \": Training a component against all the past versions of the opposite component, or a tricky mixture thereof. This is meant to avoid a component forgetting to account for earlier exploitation strategies (based on \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.nature.com/articles/s41586-019-1724-z\"\n  }, \"league exploiters in AlphaStar\"), \").\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"future exploitation\"), \": Train a component against future versions of the opposite component by anticipating short-term counterplay. Consists in running optimization across an unrolled version of a (boxed!) version of the opponent which gets a few more optimization steps (based on \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/pdf/1611.02163.pdf\"\n  }, \"unrolled GANs\"), \").\")))), mdx(\"p\", null, \"The core idea behind oversight leagues is that the evaluator is helped to better understand its systematic blindspot in relation to the agent. The agent is helped in a similar way, but unilateral training signals can be used to keep the overseer one step ahead.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/what-are-concrete-evaluator-designs\",\n    \"title\": \"what-are-concrete-evaluator-designs\"\n  }, \"[[what-are-concrete-evaluator-designs]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/what-are-concrete-unilateral-training-signals\",\n    \"title\": \"what-are-concrete-unilateral-training-signals\"\n  }, \"[[what-are-concrete-unilateral-training-signals]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/what-if-the-agent-gets-one-step-ahead-by-chance\",\n    \"title\": \"what-if-the-agent-gets-one-step-ahead-by-chance\"\n  }, \"[[what-if-the-agent-gets-one-step-ahead-by-chance]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/what-if-evaluator-overfits-to-seed\",\n    \"title\": \"what-if-evaluator-overfits-to-seed\"\n  }, \"[[what-if-evaluator-overfits-to-seed]]\"), \"\")));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"c971cb02-84ce-519e-9675-1ed9fb428398","fields":{"slug":"/oversight-leagues","title":"Oversight Leagues"}}}]},"fields":{"slug":"/ideological-inference-engines","title":"Ideological Inference Engines"}}},"pageContext":{"id":"2fc92a94-4cc4-5fb3-9c8a-ddef2f1166c7"}},"staticQueryHashes":["2098632890","2221750479","2468095761"]}