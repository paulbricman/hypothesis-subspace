{"componentChunkName":"component---node-modules-gatsby-theme-garden-src-templates-local-file-js","path":"/what-are-useful-axes-to-describe-abstraction-inductors-along","result":{"data":{"file":{"childMdx":{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"What are useful axes to describe abstraction inductors along?\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"what-are-useful-axes-to-describe-abstraction-inductors-along\"\n  }, \"What are useful axes to describe abstraction inductors along?\"), mdx(\"p\", null, \"In general abstraction inductors can be used to, well, induce particular abstractions into an ML model's conceptual framework. Those \\\"tweaks\\\" to this ontology which naturally emerges during training can be be split along various axes or spectra.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"narrow to wide scope of desired modification\"), \": If one wants to add, remove, or edit a single concept in the ML model's ontology, then it can be described as having a relatively narrow scope. In contrast, if one wants to disrupt the interrelations between many concepts, the intervention can be described as having a relatively wide scope.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"load of modification target\"), \": If one wants to modify a concept which is already loaded with connotation and nuance (e.g. \\\"human values\\\"), the modification target is relatively heavy. If one wants to tweak a novel tabula rasa concept, the target is relatively light.\")), mdx(\"p\", null, \"Using those axes, it becomes easier to describe a given intervention. For instance, consider narrow edits to a light target (e.g. a new token) towards the conjunction of nice-to-have concepts (e.g. happiness, justice, etc.), before using it to specify an objective function.\"));\n}\n;\nMDXContent.isMDXComponent = true;","outboundReferences":[],"inboundReferences":[{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Abstraction Inductors\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"abstraction-inductors\"\n  }, \"Abstraction Inductors\"), mdx(\"p\", null, \"Initial results from a recent interpretability technique (incidentally, my \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://fse.studenttheses.ub.rug.nl/27840/1/NSCv5.pdf\"\n  }, \"bachelor's thesis\"), \"), indicate that it's possible to extract parts of a transformer's internal ontology directly from latent activations, without making use of outputs at all. Analysing internal representations directly also has the benefit of making the technique modality-agnostic. Given this class of interpretability tools, what if we directly conditioned the model's ontological structure during training so as to force it to correctly learn the concept of human values in relation to other unconditioned concepts? This might either involve using a blank slate token with no other connotations or building on an existing symbol like \\\"human values\\\" and conditioning its internal representation.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/how-do-abstraction-inductors-relate-to-concrete-challenges-in-alignment\",\n    \"title\": \"how-do-abstraction-inductors-relate-to-concrete-challenges-in-alignment\"\n  }, \"[[how-do-abstraction-inductors-relate-to-concrete-challenges-in-alignment]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/what-are-useful-axes-to-describe-abstraction-inductors-along\",\n    \"title\": \"what-are-useful-axes-to-describe-abstraction-inductors-along\"\n  }, \"[[what-are-useful-axes-to-describe-abstraction-inductors-along]]\"), \"\")));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"b9f495b9-5a5b-5c58-aa27-d79c7509c592","fields":{"slug":"/abstraction-inductors","title":"Abstraction Inductors"}}}]},"fields":{"slug":"/what-are-useful-axes-to-describe-abstraction-inductors-along","title":"What are useful axes to describe abstraction inductors along?"}}},"pageContext":{"id":"33d99af8-8cfb-5aa3-98a5-52829bd0a65a"}},"staticQueryHashes":["2098632890","2221750479","2468095761"]}